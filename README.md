Credit Default Prediction Using XGBoost with SHAP Explainability
This project builds a machine learning model to predict whether a credit card client will default on their next payment.
A major focus is providing transparent and interpretable predictions using SHAP (SHapley Additive exPlanations), ensuring the model outputs are explainable for business and risk-management decisions.

ğŸš€ Project Overview
The project uses the Default of Credit Card Clients Dataset and walks through the complete ML workflow:
âœ” Data Cleaning & Preprocessing


Removed index column (Unnamed: 0)


Handled categorical and numeric separation


Fixed non-numeric values in target variable


Filled missing values appropriately


Renamed features from X1..X23 to meaningful real-world names


âœ” Model Training


Model used: XGBoost Classifier


Train/Test split with stratification


End-to-end pipeline built using Scikit-Learn


âœ” Model Evaluation (Test Set)
MetricScoreAUC0.7761Precision0.4725Recall0.6142F1-score0.5341Accuracy0.76
Confusion Matrix:
[[3763  910]
 [ 512  815]]


ğŸ” SHAP Interpretability
SHAP was used to explain both global (feature importance across all clients) and local (per-client) behaviour of the model.
ğŸ”¹ Global SHAP â€” Top 5 Most Important Features


PAY_0 â€” Most recent repayment status


LIMIT_BAL â€” Credit limit


BILL_AMT1 â€” Most recent bill amount


PAY_AMT2 â€” Repayment two months ago


PAY_AMT1 â€” Repayment last month


Global SHAP outputs include:


shap_summary.png â€” Summary scatter plot


shap_bar.png â€” Bar plot of mean |SHAP| values


global_shap_importance.csv â€” Numerical feature importances



ğŸ¯ Local SHAP Explanations (3 Case Studies)
Three representative cases were selected:1ï¸âƒ£ Low-Risk Client


Model predicted very low probability of default


SHAP shows strong negative contributions from large past payments


2ï¸âƒ£ High-Risk Client


Model predicted high probability of default


Strong positive SHAP contributions from poor repayment status (PAY_0, PAY_2, etc.)


3ï¸âƒ£ Surprising Case


The model predicted default against intuition


Local SHAP values reveal feature interactions causing the unusual prediction


For each case, the following files are included:


local_shap_<case>.csv


local_shap_bar_<case>.png


explanation_<case>.txt


These provide a complete breakdown of how features influenced the prediction.

ğŸ“ Repository Structure
your-repo/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ credit_default_shap.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ default_credit.csv   (optional â€“ or provide download link)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pipeline_xgb.pkl
â”‚   â””â”€â”€ pipeline_xgb_best.pkl   (optional)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ metrics.txt
â”‚   â”œâ”€â”€ top5_shap.csv
â”‚   â”œâ”€â”€ executive_summary.txt
â”‚   â”œâ”€â”€ shap_summary.png
â”‚   â”œâ”€â”€ shap_bar.png
â”‚   â”œâ”€â”€ global_shap_importance.csv
â”‚   â”œâ”€â”€ local_shap_low_risk.csv
â”‚   â”œâ”€â”€ local_shap_high_risk.csv
â”‚   â”œâ”€â”€ local_shap_surprising.csv
â”‚   â”œâ”€â”€ local_shap_bar_low_risk.png
â”‚   â”œâ”€â”€ local_shap_bar_high_risk.png
â”‚   â”œâ”€â”€ local_shap_bar_surprising.png
â”‚   â”œâ”€â”€ explanation_low_risk.txt
â”‚   â”œâ”€â”€ explanation_high_risk.txt
â”‚   â””â”€â”€ explanation_surprising.txt


ğŸ›  How to Run This Project


Clone the repository:
git clone https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git



Open the notebook in Google Colab:


Upload to Colab


Ensure dataset is in /content/drive/MyDrive/ or adjust path




Run all cells sequentially


Outputs are automatically generated in the outputs/ folder



ğŸ“Œ Key Business Insights


Recent repayment behavior (PAY_0, PAY_2, â€¦) is the strongest predictor of risk


Higher credit limits reduce default risk


Larger recent repayments significantly decrease risk


SHAP values allow auditors and financial analysts to justify each prediction



Credit Default Prediction Using XGBoost with SHAP Explainability
This project builds a machine learning model to predict whether a credit card client will default on their next payment.
A major focus is providing transparent and interpretable predictions using SHAP (SHapley Additive exPlanations), ensuring the model outputs are explainable for business and risk-management decisions.

ğŸš€ Project Overview
The project uses the Default of Credit Card Clients Dataset and walks through the complete ML workflow:
âœ” Data Cleaning & Preprocessing


Removed index column (Unnamed: 0)


Handled categorical and numeric separation


Fixed non-numeric values in target variable


Filled missing values appropriately


Renamed features from X1..X23 to meaningful real-world names


âœ” Model Training


Model used: XGBoost Classifier


Train/Test split with stratification


End-to-end pipeline built using Scikit-Learn


âœ” Model Evaluation (Test Set)
MetricScoreAUC0.7761Precision0.4725Recall0.6142F1-score0.5341Accuracy0.76
Confusion Matrix:
[[3763  910]
 [ 512  815]]


ğŸ” SHAP Interpretability
SHAP was used to explain both global (feature importance across all clients) and local (per-client) behaviour of the model.
ğŸ”¹ Global SHAP â€” Top 5 Most Important Features


PAY_0 â€” Most recent repayment status


LIMIT_BAL â€” Credit limit


BILL_AMT1 â€” Most recent bill amount


PAY_AMT2 â€” Repayment two months ago


PAY_AMT1 â€” Repayment last month


Global SHAP outputs include:


shap_summary.png â€” Summary scatter plot


shap_bar.png â€” Bar plot of mean |SHAP| values


global_shap_importance.csv â€” Numerical feature importances



ğŸ¯ Local SHAP Explanations (3 Case Studies)
Three representative cases were selected:
1ï¸âƒ£ Low-Risk Client


Model predicted very low probability of default


SHAP shows strong negative contributions from large past payments


2ï¸âƒ£ High-Risk Client


Model predicted high probability of default


Strong positive SHAP contributions from poor repayment status (PAY_0, PAY_2, etc.)


3ï¸âƒ£ Surprising Case


The model predicted default against intuition


Local SHAP values reveal feature interactions causing the unusual prediction


For each case, the following files are included:


local_shap_<case>.csv


local_shap_bar_<case>.png


explanation_<case>.txt


These provide a complete breakdown of how features influenced the prediction.

ğŸ“ Repository Structure
your-repo/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ credit_default_shap.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ default_credit.csv   (optional â€“ or provide download link)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pipeline_xgb.pkl
â”‚   â””â”€â”€ pipeline_xgb_best.pkl   (optional)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ metrics.txt
â”‚   â”œâ”€â”€ top5_shap.csv
â”‚   â”œâ”€â”€ executive_summary.txt
â”‚   â”œâ”€â”€ shap_summary.png
â”‚   â”œâ”€â”€ shap_bar.png
â”‚   â”œâ”€â”€ global_shap_importance.csv
â”‚   â”œâ”€â”€ local_shap_low_risk.csv
â”‚   â”œâ”€â”€ local_shap_high_risk.csv
â”‚   â”œâ”€â”€ local_shap_surprising.csv
â”‚   â”œâ”€â”€ local_shap_bar_low_risk.png
â”‚   â”œâ”€â”€ local_shap_bar_high_risk.png
â”‚   â”œâ”€â”€ local_shap_bar_surprising.png
â”‚   â”œâ”€â”€ explanation_low_risk.txt
â”‚   â”œâ”€â”€ explanation_high_risk.txt
â”‚   â””â”€â”€ explanation_surprising.txt


ğŸ›  How to Run This Project


Clone the repository:
git clone https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git



Open the notebook in Google Colab:


Upload to Colab


Ensure dataset is in /content/drive/MyDrive/ or adjust path




Run all cells sequentially


Outputs are automatically generated in the outputs/ folder



ğŸ“Œ Key Business Insights


Recent repayment behavior (PAY_0, PAY_2, â€¦) is the strongest predictor of risk


Higher credit limits reduce default risk


Larger recent repayments significantly decrease risk


SHAP values allow auditors and financial analysts to justify each prediction